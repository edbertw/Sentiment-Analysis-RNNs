{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7235569,"sourceType":"datasetVersion","datasetId":4189989},{"sourceId":40627787,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T16:07:29.436995Z","iopub.execute_input":"2024-07-17T16:07:29.437641Z","iopub.status.idle":"2024-07-17T16:07:35.396209Z","shell.execute_reply.started":"2024-07-17T16:07:29.437609Z","shell.execute_reply":"2024-07-17T16:07:35.395257Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis/IMDB_dataset.csv\")\nprint(data.head())\n\nfrom string import punctuation\ndef remove_punc(text):\n    text = text.lower()\n    return (\"\".join(i for i in text if i not in punctuation))\n\ndata[\"review\"] = data[\"review\"].apply(remove_punc)\nprint(data.head())\nX = data[\"review\"].values\ny = data[\"sentiment\"].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(X_train.shape)\nprint(X_test.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T16:08:32.269461Z","iopub.execute_input":"2024-07-17T16:08:32.269919Z","iopub.status.idle":"2024-07-17T16:08:41.658168Z","shell.execute_reply.started":"2024-07-17T16:08:32.269886Z","shell.execute_reply":"2024-07-17T16:08:41.657145Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n                                              review sentiment\n0  one of the other reviewers has mentioned that ...  positive\n1  a wonderful little production br br the filmin...  positive\n2  i thought this was a wonderful way to spend ti...  positive\n3  basically theres a family where a little boy j...  negative\n4  petter matteis love in the time of money is a ...  positive\n(37500,)\n(12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def process(string):\n    string = re.sub(r\"[^\\w\\s]\", '', string)\n    string = re.sub(r\"\\d\", '', string)\n    string = re.sub(r\"\\s+\", '', string)\n    return string\n\ndef tokenize(X_train,y_train,X_test,y_test):\n    words = []\n    stop_words = set(stopwords.words('english')) \n    for x in X_train:\n        for word in x.split():\n            word = process(word)\n            if word not in stop_words and word != '':\n                words.append(word)\n                \n    counts = Counter(words)\n    vocab = sorted(counts, key=counts.get, reverse=True)[:1000]\n    vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)}\n    new_X_train = []\n    new_X_test = []\n    for s in X_train:\n            new_X_train.append([vocab_to_int[process(word)] for word in s.split() \n                                     if process(word) in vocab_to_int.keys()])\n    for s in X_test:\n            new_X_test.append([vocab_to_int[process(word)] for word in s.split() \n                                    if process(word) in vocab_to_int.keys()])\n            \n    new_y_train = [1 if label =='positive' else 0 for label in y_train]  \n    new_y_test = [1 if label =='positive' else 0 for label in y_test]\n    return new_X_train, new_y_train,new_X_test, new_y_test, vocab_to_int\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:21:25.929869Z","iopub.execute_input":"2024-07-08T15:21:25.930771Z","iopub.status.idle":"2024-07-08T15:21:25.945328Z","shell.execute_reply.started":"2024-07-08T15:21:25.930733Z","shell.execute_reply":"2024-07-08T15:21:25.944383Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train,y_train,X_test,y_test,vocab_to_int = tokenize(X_train,y_train,X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:21:28.799864Z","iopub.execute_input":"2024-07-08T15:21:28.800204Z","iopub.status.idle":"2024-07-08T15:23:18.502311Z","shell.execute_reply.started":"2024-07-08T15:21:28.800177Z","shell.execute_reply":"2024-07-08T15:23:18.501484Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''\nnon_zero_idx_train = [ii for ii, review in enumerate(X_train) if len(review) != 0]\nnon_zero_idx_test = [ii for ii, review in enumerate(X_test) if len(review) != 0]\nX_train = [X_train[ii] for ii in non_zero_idx_train]\nX_test = [X_test[ii] for ii in non_zero_idx_test]\ny_train = np.array([y_train[ii] for ii in non_zero_idx_train])\ny_test = np.array([y_test[ii] for ii in non_zero_idx_test])\nprint(len(X_train), len(X_test))\n'''","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:30:36.894960Z","iopub.execute_input":"2024-07-08T10:30:36.895732Z","iopub.status.idle":"2024-07-08T10:30:36.933239Z","shell.execute_reply.started":"2024-07-08T10:30:36.895694Z","shell.execute_reply":"2024-07-08T10:30:36.932355Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"37499 12500\n","output_type":"stream"}]},{"cell_type":"code","source":"def padding(sentence, seqLength):\n    #determine shape\n    features = np.zeros((len(sentence), seqLength), dtype=int)\n    for i, row in enumerate(sentence):\n        if len(row) != 0:\n            features[i, -len(row):] = np.array(row)[:seqLength]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:25:29.198051Z","iopub.execute_input":"2024-07-08T15:25:29.198764Z","iopub.status.idle":"2024-07-08T15:25:29.204210Z","shell.execute_reply.started":"2024-07-08T15:25:29.198735Z","shell.execute_reply":"2024-07-08T15:25:29.203242Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train_pad = padding(X_train,500)\nX_test_pad = padding(X_test,500)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:25:31.492105Z","iopub.execute_input":"2024-07-08T15:25:31.492479Z","iopub.status.idle":"2024-07-08T15:25:32.020782Z","shell.execute_reply.started":"2024-07-08T15:25:31.492451Z","shell.execute_reply":"2024-07-08T15:25:32.020024Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(X_train_pad), torch.from_numpy(np.array(y_train)))\nvalid_data = TensorDataset(torch.from_numpy(X_test_pad), torch.from_numpy(np.array(y_test)))\n\nbatch_size = 50\n\n#Shuffle for generalization\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n\n#Obtain a batch of the training data\ndataiter = iter(train_loader)\nsampleX, sampley = next(dataiter)\n\nprint('Sample input size: ', sampleX.size())\nprint('Sample input: \\n', sampleX)\nprint('Sample input: \\n', sampley)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:25:34.222333Z","iopub.execute_input":"2024-07-08T15:25:34.222676Z","iopub.status.idle":"2024-07-08T15:25:34.294789Z","shell.execute_reply.started":"2024-07-08T15:25:34.222652Z","shell.execute_reply":"2024-07-08T15:25:34.293909Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Sample input size:  torch.Size([50, 500])\nSample input: \n tensor([[  0,   0,   0,  ..., 661, 101, 451],\n        [  0,   0,   0,  ...,  91,  30,  62],\n        [  0,   0,   0,  ..., 213,  18, 163],\n        ...,\n        [  0,   0,   0,  ..., 545, 336, 654],\n        [  0,   0,   0,  ..., 182,  13,  92],\n        [  0,   0,   0,  ...,  49,  81,  10]])\nSample input: \n tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n        0, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:25:37.936611Z","iopub.execute_input":"2024-07-08T15:25:37.936957Z","iopub.status.idle":"2024-07-08T15:25:37.972604Z","shell.execute_reply.started":"2024-07-08T15:25:37.936930Z","shell.execute_reply":"2024-07-08T15:25:37.971652Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training on GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclass SentimentRNN(nn.Module):\n    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n        super(SentimentRNN,self).__init__()\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.no_layers = no_layers\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim, num_layers=no_layers, batch_first=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(self.hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n       \n    def forward(self,x,hidden):\n        batch_size = x.size(0)\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        #Hidden state\n        weight = next(self.parameters()).data\n        if (train_on_gpu):\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.no_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:36:42.268568Z","iopub.execute_input":"2024-07-08T15:36:42.269283Z","iopub.status.idle":"2024-07-08T15:36:42.280272Z","shell.execute_reply.started":"2024-07-08T15:36:42.269249Z","shell.execute_reply":"2024-07-08T15:36:42.279357Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"no_layers = 2\nvocab_size = len(vocab_to_int) + 1\nembedding_dim = 64\noutput_dim = 1\nhidden_dim = 256\n\nmodel = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:36:45.213401Z","iopub.execute_input":"2024-07-08T15:36:45.213738Z","iopub.status.idle":"2024-07-08T15:36:45.230134Z","shell.execute_reply.started":"2024-07-08T15:36:45.213714Z","shell.execute_reply":"2024-07-08T15:36:45.229206Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"SentimentRNN(\n  (embedding): Embedding(1001, 64)\n  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Training\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:36:47.886106Z","iopub.execute_input":"2024-07-08T15:36:47.886477Z","iopub.status.idle":"2024-07-08T15:36:49.286496Z","shell.execute_reply.started":"2024-07-08T15:36:47.886448Z","shell.execute_reply":"2024-07-08T15:36:49.285536Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"clip = 5\nepochs = 4 \n\ndef acc(pred,label):\n    pred = torch.round(pred.squeeze())\n    return torch.sum(pred == label.squeeze()).item()\n\nif(train_on_gpu):\n    model.cuda()\n    \nfor epoch in range(epochs):\n    train_losses = []\n    train_acc = 0.0\n    #train mode\n    model.train() \n    h = model.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        if(train_on_gpu):\n            inputs, labels = inputs.cuda(), labels.cuda()  \n        h = tuple([each.data for each in h])\n        model.zero_grad()\n        output,h = model(inputs,h)\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        train_losses.append(loss.item())\n        accuracy = acc(output,labels)\n        train_acc += accuracy\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\ntest_losses = []\nnum_correct = 0\n\nh = model.init_hidden(batch_size)\n#Testing mode\nmodel.eval()\nfor inputs, labels in valid_loader:\n    h = tuple([each.data for each in h])\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n    output, h = model(inputs, h)\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    pred = torch.round(output.squeeze()) \n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\ntest_acc = num_correct/len(valid_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:36:52.413926Z","iopub.execute_input":"2024-07-08T15:36:52.415053Z","iopub.status.idle":"2024-07-08T15:41:30.976630Z","shell.execute_reply.started":"2024-07-08T15:36:52.415019Z","shell.execute_reply":"2024-07-08T15:41:30.975591Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test loss: 0.345\nTest accuracy: 0.853\n","output_type":"stream"}]},{"cell_type":"code","source":"h = model.init_hidden(50)\nh = tuple(each.data for each in h)\nprint(h)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:21.260511Z","iopub.execute_input":"2024-07-08T17:06:21.261324Z","iopub.status.idle":"2024-07-08T17:06:21.271811Z","shell.execute_reply.started":"2024-07-08T17:06:21.261291Z","shell.execute_reply":"2024-07-08T17:06:21.270903Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_review(test_review):\n    test_review = test_review.lower()\n    test_text = ''.join([i for i in test_review if i not in punctuation])\n    test_words = test_text.split()\n    test_ints = []\n    test_ints.append([vocab_to_int.get(word, 0) for word in test_words])\n    return test_ints\n\ndef predict(net, test_review, sequence_length=500):\n    model.eval()\n    test_ints = tokenize_review(test_review)\n    seq_length=sequence_length\n    features = padding(test_ints, seq_length)\n    feature_tensor = torch.from_numpy(features)\n    batch_size = feature_tensor.size(0)\n    h = net.init_hidden(batch_size)\n    if(train_on_gpu):\n        feature_tensor = feature_tensor.cuda()\n    output, h = model(feature_tensor, h)\n    print('Prediction value: {:.6f}'.format(output.item()))\n    if(output.item() > 0.5):\n        print(\"Positive review detected! With probability of:\",output.item())\n    else:\n        print(\"Negative review detected! With probability of:\", (1 - output.item()))\n        \ntest_review = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\npredict(model, test_review, 500)        ","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:46:27.732555Z","iopub.execute_input":"2024-07-08T15:46:27.732900Z","iopub.status.idle":"2024-07-08T15:46:27.761769Z","shell.execute_reply.started":"2024-07-08T15:46:27.732872Z","shell.execute_reply":"2024-07-08T15:46:27.760861Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Prediction value: 0.019337\nNegative review detected! With probability of: 0.980663113296032\n","output_type":"stream"}]},{"cell_type":"code","source":"#Deploying PyTorch using Tracing Method\n'''\nimport torch\nclass SentimentRNN(nn.Module):\n    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n        super(SentimentRNN,self).__init__()\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.no_layers = no_layers\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim, num_layers=no_layers, batch_first=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(self.hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self,x,hidden):\n        batch_size = x.size(0)\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        #Hidden state\n        weight = next(self.parameters()).data\n        if (train_on_gpu):\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.no_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden\n'''\nexample = torch.zeros(50,500, dtype = torch.int)\nif train_on_gpu:\n    example = example.cuda()\nprint(example)\nprint(hidden)\ntraced_script_module = torch.jit.trace(model, (example,h))\ntraced_script_module.save(\"sentiment_rnn.pt\")\nnew_model = torch.jit.load(\"sentiment_rnn.pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:52.204005Z","iopub.execute_input":"2024-07-08T17:06:52.205081Z","iopub.status.idle":"2024-07-08T17:06:52.502525Z","shell.execute_reply.started":"2024-07-08T17:06:52.205044Z","shell.execute_reply":"2024-07-08T17:06:52.501530Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32)\ntensor([[[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]],\n\n        [[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]],\n\n        [[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]],\n\n        ...,\n\n        [[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]],\n\n        [[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]],\n\n        [[0, 0],\n         [0, 0],\n         [0, 0],\n         ...,\n         [0, 0],\n         [0, 0],\n         [0, 0]]], device='cuda:0', dtype=torch.int32)\n","output_type":"stream"}]}]}
